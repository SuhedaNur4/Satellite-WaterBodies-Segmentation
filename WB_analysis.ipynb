{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ee2acc6",
   "metadata": {},
   "source": [
    "### 1. Imports and Utility Functions\n",
    "\n",
    "This cell imports the required libraries and custom utility functions used throughout the notebook.  \n",
    "The utilities handle image reading, segmentation, metric computation, visualization, and dataset path management.  \n",
    "All core processing logic is encapsulated in `WB_utils.py` to keep the notebook clean and focused on experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05b33657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from WB_utils import (\n",
    "    read_rgb,\n",
    "    read_gray,\n",
    "    segmentation_pipeline,\n",
    "    compute_metrics,\n",
    "    save_detailed_visuals,\n",
    "    save_metrics_barchart,\n",
    "    get_dataset_paths,\n",
    "    ensure_mask_size_like_image\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28765849",
   "metadata": {},
   "source": [
    "### 2. Dataset Processing and Performance Evaluation\n",
    "\n",
    "This cell iterates over the dataset, applies the segmentation pipeline to each image, and compares the predicted masks with the ground truth masks.  \n",
    "For each sample, standard segmentation metrics (Accuracy, Precision, Recall, F1-Score, and IoU) are computed.  \n",
    "A subset of images is visualized for qualitative analysis, and the average performance metrics over the entire dataset are summarized and plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79af90f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Found 2841 images and 2841 masks.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.5596575103358492,\n",
       " 'Precision': 0.38218908485917974,\n",
       " 'Recall': 0.4984269101635385,\n",
       " 'F1-Score': 0.3878490752239281,\n",
       " 'IoU': 0.2958232829889976}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_paths, mask_paths = get_dataset_paths(verbose=True)\n",
    "\n",
    "metrics = {\n",
    "    \"Accuracy\": [],\n",
    "    \"Precision\": [],\n",
    "    \"Recall\": [],\n",
    "    \"F1-Score\": [],\n",
    "    \"IoU\": []\n",
    "}\n",
    "\n",
    "NUM_SAMPLE_IMAGES = 5\n",
    "\n",
    "for i, (img_p, mask_p) in enumerate(zip(image_paths, mask_paths)):\n",
    "    name = os.path.basename(img_p)\n",
    "\n",
    "    img = read_rgb(img_p, verbose=True)\n",
    "    gt  = read_gray(mask_p, verbose=True)\n",
    "\n",
    "    if img is None or gt is None:\n",
    "        continue\n",
    "\n",
    "    gt = ensure_mask_size_like_image(gt, img)\n",
    "\n",
    "    pred, s_eq, otsu_val = segmentation_pipeline(img)\n",
    "\n",
    "    acc, prec, rec, f1, iou = compute_metrics(gt, pred)\n",
    "\n",
    "    metrics[\"Accuracy\"].append(acc)\n",
    "    metrics[\"Precision\"].append(prec)\n",
    "    metrics[\"Recall\"].append(rec)\n",
    "    metrics[\"F1-Score\"].append(f1)\n",
    "    metrics[\"IoU\"].append(iou)\n",
    "\n",
    "    if i < NUM_SAMPLE_IMAGES:\n",
    "        save_detailed_visuals(img, s_eq, gt, pred, otsu_val, name)\n",
    "\n",
    "avg_metrics = {k: (float(np.mean(v)) if len(v) else 0.0) for k, v in metrics.items()}\n",
    "save_metrics_barchart(avg_metrics)\n",
    "\n",
    "avg_metrics\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proje_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
